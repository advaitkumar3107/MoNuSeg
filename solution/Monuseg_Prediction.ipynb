{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Monuseg_Prediction","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPRy//3hfYwsovSTj5b+gSn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"lsyrRl7gEIL5","colab_type":"code","outputId":"05767fdb-d99c-4a74-ea45-c73a48f3b006","executionInfo":{"status":"ok","timestamp":1588035694722,"user_tz":-330,"elapsed":1318,"user":{"displayName":"advait kumar","photoUrl":"","userId":"02777440050749849428"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","from sklearn.metrics import jaccard_score\n","import os\n","import sys\n","import numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from PIL import Image\n","import torchvision.transforms.functional as TF\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","os.chdir('/content/drive/My Drive/amit sethi')\n","\n","ROOT_DIR = os.path.abspath(\"../../\")\n","sys.path.append(ROOT_DIR)\n","\n","# Data Path\n","TEST_PATH = 'Datasets/test/'\n","TRAIN_PATH = 'Datasets/nucleus/'\n","\n","# Get train and test IDs\n","test_ids = next(os.walk(TEST_PATH))[1]\n","train_ids = next(os.walk(TRAIN_PATH))[1]"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rHBuCsHSEoxC","colab_type":"code","colab":{}},"source":["#### Defining Dataset ####\n","\n","class NucleusDataset(torch.utils.data.Dataset):\n","  def __init__(self, images, masks, train = True):\n","    \n","    self.images = images\n","    self.masks = masks\n","    self.train = train\n","\n","\n","  def transforms(self, image, mask):\n","    \n","    if random.random() > 0.5:\n","      image = TF.hflip(image)\n","      mask = TF.hflip(mask)\n","\n","    if random.random() > 0.5:\n","      image = TF.hflip(image)\n","      mask = TF.hflip(mask)\n","\n","    if random.random() > 0.8:\n","      image = TF.affine(image, 90, (100,100), 1.0, 45.0)\n","      mask = TF.affine(mask, 90, (100,100), 1.0, 45.0)\n","\n","    image = TF.to_tensor(image)\n","    mask = TF.to_tensor(mask)\n","\n","    return image,mask\n","\n","\n","  def __len__(self):\n","    return len(self.images)\n","\n","  def __getitem__(self,index): \n","\n","    image = self.images[index]\n","    mask = self.masks[index]\n","\n","    if self.train:\n","      x,y = self.transforms(image, mask)\n","\n","    else:\n","      x = TF.to_tensor(image)\n","      y = TF.to_tensor(mask)\n","\n","    return x,y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XAQ9SY8Eo1o","colab_type":"code","colab":{}},"source":["### utility functions ###\n","\n","def train_creator(ids, root):\n","  images = []\n","  masks = []\n","\n","  for i in range(len(ids)):\n","\n","    image_name = root + ids[i] + '/images/' + ids[i] + '.png'\n","    mask_name = root + ids[i] + '/masks/' + ids[i] + '.png'\n","    original_image = Image.open(image_name)\n","    original_mask = Image.open(mask_name)\n","\n","    width, height = original_image.size\n","    for i in range(0,height,200):\n","      for j in range(0,width,200):\n","        box = (j,i,j+200, i+200)\n","        image = original_image.crop(box)\n","        mask = original_mask.crop(box)\n","        images.append(image)\n","        masks.append(mask)\n","    \n","  return images, masks\n","\n","def predict(model, dataloader):\n","  image, masks = next(iter(dataloader))\n","  length = len(dataloader)\n","  outputs = model(image.cuda())\n","\n","  return image,outputs, masks\n","\n","def prediction_score(model1_directory, model2_directory, test_loader):\n","  \n","  checkpoints = torch.load(model1_directory)\n","  model1 = checkpoints['model']\n","\n","  checkpoints = torch.load(model2_directory)\n","  model2 = checkpoints['model']\n","\n","  score1 = 0\n","  score2 = 0\n","  ensembled_max_score = 0\n","  ensembled_min_score = 0\n","\n","  for i, (images, masks) in enumerate(test_loader):\n","    outputs1 = model1(images.cuda())\n","    outputs2 = model2(images.cuda())\n","\n","    ensembled_max = torch.max(outputs1, outputs2)\n","    ensembled_min = torch.min(outputs1, outputs2)\n","    \n","    masks = masks.round()\n","    masks = masks.cpu()\n","    masks = np.array(masks).ravel()\n","\n","    outputs1 = outputs1.round()\n","    outputs1 = outputs1.detach().cpu()\n","    outputs1 = np.array(outputs1).ravel()\n","\n","    outputs2 = outputs2.round()\n","    outputs2 = outputs2.detach().cpu()\n","    outputs2 = np.array(outputs2).ravel()\n","\n","    ensembled_max = ensembled_max.round()\n","    ensembled_max = ensembled_max.detach().cpu()\n","    ensembled_max = np.array(ensembled_max).ravel()\n","\n","    ensembled_min = ensembled_min.round()\n","    ensembled_min = ensembled_min.detach().cpu()\n","    ensembled_min = np.array(ensembled_min).ravel()\n","    \n","    score1 = score1 + jaccard_score(masks, outputs1)\n","    score2 = score2 + jaccard_score(masks, outputs2)\n","    ensembled_max_score = ensembled_max_score + jaccard_score(masks, ensembled_max)\n","    ensembled_min_score = ensembled_min_score + jaccard_score(masks, ensembled_min)\n","\n","\n","  score1 = score1/(i+1)\n","  score2 = score2/(i+1)\n","  ensembled_max_score = ensembled_max_score/(i+1)\n","  ensembled_min_score = ensembled_min_score/(i+1)\n","\n","  print('1st model prediction : %.4f' % (score1))\n","  print('2nd model prediction : %.4f' % (score2))\n","  print('Ensemble model with max of outputs prediction : %.4f' % (ensembled_max_score))\n","  print('Ensemble model with min of outputs prediction : %.4f' % (ensembled_min_score))\n","\n","def show(img):\n","    npimg = img.detach().numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QPuRJHtkEo52","colab_type":"code","colab":{}},"source":["### Defining UNET Architecture ###\n","class unet(nn.Module):\n","\n","  def contracting_block(self, in_channels, out_channels):\n","    block = nn.Sequential(nn.Conv2d(in_channels,out_channels, 3, padding = 1), nn.ReLU(), nn.BatchNorm2d(out_channels),\n","                          nn.Conv2d(out_channels, out_channels, 3, padding  = 1), nn.ReLU(), nn.BatchNorm2d(out_channels))\n","    \n","    return block\n","\n","  def expansive_block(self, in_channels, mid_channel, out_channels):\n","    block = nn.Sequential(nn.Conv2d(in_channels, mid_channel, 3, padding = 1), nn.ReLU(), nn.BatchNorm2d(mid_channel),\n","                          nn.Conv2d(mid_channel, mid_channel, 3, padding = 1), nn.ReLU(), nn.BatchNorm2d(mid_channel),\n","                          nn.ConvTranspose2d(mid_channel, out_channels, 3, 2,padding = 1,output_padding = 1))\n","    return block\n","\n","  def final_block(self, in_channels, mid_channel, out_channels):\n","    block = nn.Sequential(nn.Conv2d(in_channels, mid_channel, 3, padding = 1), nn.ReLU(), nn.BatchNorm2d(mid_channel),\n","                          nn.Conv2d(mid_channel, mid_channel, 3, padding = 1), nn.ReLU(), nn.BatchNorm2d(mid_channel), \n","                          nn.Conv2d(mid_channel, out_channels, 3, padding =1), nn.Sigmoid())\n","    return block\n","\n","  def __init__(self, in_channel, out_channel):\n","    super(unet, self).__init__()\n","\n","    self.encode1 = self.contracting_block(in_channel, 64)\n","    self.maxpool1 = nn.MaxPool2d(kernel_size = 2)\n","    self.encode2 = self.contracting_block(64,128)\n","    self.maxpool2 = nn.MaxPool2d(2)\n","    self.encode3 = self.contracting_block(128,256)\n","    self.maxpool3 = nn.MaxPool2d(2)\n","\n","    self.bottleneck = self.expansive_block(256,512,256)\n","\n","    self.decode3 = self.expansive_block(512,256,128)\n","    self.decode2 = self.expansive_block(256,128,64)\n","    \n","    self.final_layer = self.final_block(128,64,out_channel)\n","\n","  \n","  def crop_and_concat(self, upsampled, bypass):\n","      c = (bypass.size()[2] - upsampled.size()[2]) // 2\n","      bypass = F.pad(bypass, (-c, -c, -c, -c))\n","      return torch.cat((upsampled, bypass), 1)\n","\n","\n","  def forward(self,x):\n","    encode1 = self.encode1(x)\n","    maxpool1 = self.maxpool1(encode1)\n","    encode2 = self.encode2(maxpool1)\n","    maxpool2 = self.maxpool2(encode2)\n","    encode3 = self.encode3(maxpool2)\n","    maxpool3 = self.maxpool3(encode3)\n","\n","    bottleneck = self.bottleneck(maxpool3)\n","\n","    decode3 = self.crop_and_concat(bottleneck, encode3)\n","    cat_layer2 = self.decode3(decode3)\n","    decode2 = self.crop_and_concat(cat_layer2, encode2)\n","    cat_layer1 = self.decode2(decode2)\n","    decode1 = self.crop_and_concat(cat_layer1, encode1)\n","    final = self.final_layer(decode1)\n","\n","    return final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"afe6XpTaEozx","colab_type":"code","colab":{}},"source":["train_images, train_masks = train_creator(train_ids, TRAIN_PATH)\n","train_dataset = NucleusDataset(train_images, train_masks, False)\n","\n","test_images, test_masks = train_creator(test_ids, TEST_PATH)\n","test_dataset = NucleusDataset(test_images, test_masks, False)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 25, shuffle = False, num_workers = 2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 25, shuffle = False, num_workers = 2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6axlAA_Eoux","colab_type":"code","colab":{}},"source":["BatchNorm2d = nn.BatchNorm2d\n","BN_MOMENTUM = 0.01\n","\n","def conv3x3(in_planes, out_planes, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = BatchNorm2d(planes, momentum=BN_MOMENTUM)\n","        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n","                               bias=False)\n","        self.bn3 = BatchNorm2d(planes * self.expansion,\n","                               momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class HighResolutionModule(nn.Module):\n","    def __init__(self, num_branches, blocks, num_blocks, num_inchannels,\n","                 num_channels, fuse_method, multi_scale_output=True):\n","        super(HighResolutionModule, self).__init__()\n","        self._check_branches(\n","            num_branches, blocks, num_blocks, num_inchannels, num_channels)\n","\n","        self.num_inchannels = num_inchannels\n","        self.fuse_method = fuse_method\n","        self.num_branches = num_branches\n","\n","        self.multi_scale_output = multi_scale_output\n","\n","        self.branches = self._make_branches(\n","            num_branches, blocks, num_blocks, num_channels)\n","        self.fuse_layers = self._make_fuse_layers()\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def _check_branches(self, num_branches, blocks, num_blocks,\n","                        num_inchannels, num_channels):\n","        if num_branches != len(num_blocks):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_BLOCKS({})'.format(\n","                num_branches, len(num_blocks))\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_channels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_CHANNELS({})'.format(\n","                num_branches, len(num_channels))\n","            raise ValueError(error_msg)\n","\n","        if num_branches != len(num_inchannels):\n","            error_msg = 'NUM_BRANCHES({}) <> NUM_INCHANNELS({})'.format(\n","                num_branches, len(num_inchannels))\n","            raise ValueError(error_msg)\n","\n","    def _make_one_branch(self, branch_index, block, num_blocks, num_channels,\n","                         stride=1):\n","        downsample = None\n","        if stride != 1 or \\\n","           self.num_inchannels[branch_index] != num_channels[branch_index] * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.num_inchannels[branch_index],\n","                          num_channels[branch_index] * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(num_channels[branch_index] * block.expansion,\n","                            momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.num_inchannels[branch_index],\n","                            num_channels[branch_index], stride, downsample))\n","        self.num_inchannels[branch_index] = \\\n","            num_channels[branch_index] * block.expansion\n","        for i in range(1, num_blocks[branch_index]):\n","            layers.append(block(self.num_inchannels[branch_index],\n","                                num_channels[branch_index]))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_branches(self, num_branches, block, num_blocks, num_channels):\n","        branches = []\n","\n","        for i in range(num_branches):\n","            branches.append(\n","                self._make_one_branch(i, block, num_blocks, num_channels))\n","\n","        return nn.ModuleList(branches)\n","\n","    def _make_fuse_layers(self):\n","        if self.num_branches == 1:\n","            return None\n","\n","        num_branches = self.num_branches\n","        num_inchannels = self.num_inchannels\n","        fuse_layers = []\n","        for i in range(num_branches if self.multi_scale_output else 1):\n","            fuse_layer = []\n","            for j in range(num_branches):\n","                if j > i:\n","                    fuse_layer.append(nn.Sequential(\n","                        nn.Conv2d(num_inchannels[j],\n","                                  num_inchannels[i],\n","                                  1,\n","                                  1,\n","                                  0,\n","                                  bias=False),\n","                        BatchNorm2d(num_inchannels[i], momentum=BN_MOMENTUM)))\n","                elif j == i:\n","                    fuse_layer.append(None)\n","                else:\n","                    conv3x3s = []\n","                    for k in range(i-j):\n","                        if k == i - j - 1:\n","                            num_outchannels_conv3x3 = num_inchannels[i]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3, \n","                                            momentum=BN_MOMENTUM)))\n","                        else:\n","                            num_outchannels_conv3x3 = num_inchannels[j]\n","                            conv3x3s.append(nn.Sequential(\n","                                nn.Conv2d(num_inchannels[j],\n","                                          num_outchannels_conv3x3,\n","                                          3, 2, 1, bias=False),\n","                                BatchNorm2d(num_outchannels_conv3x3,\n","                                            momentum=BN_MOMENTUM),\n","                                nn.ReLU(inplace=True)))\n","                    fuse_layer.append(nn.Sequential(*conv3x3s))\n","            fuse_layers.append(nn.ModuleList(fuse_layer))\n","\n","        return nn.ModuleList(fuse_layers)\n","\n","    def get_num_inchannels(self):\n","        return self.num_inchannels\n","\n","    def forward(self, x):\n","        if self.num_branches == 1:\n","            return [self.branches[0](x[0])]\n","\n","        for i in range(self.num_branches):\n","            x[i] = self.branches[i](x[i])\n","\n","        x_fuse = []\n","        for i in range(len(self.fuse_layers)):\n","            y = x[0] if i == 0 else self.fuse_layers[i][0](x[0])\n","            for j in range(1, self.num_branches):\n","                if i == j:\n","                    y = y + x[j]\n","                elif j > i:\n","                    width_output = x[i].shape[-1]\n","                    height_output = x[i].shape[-2]\n","                    y = y + F.interpolate(\n","                        self.fuse_layers[i][j](x[j]),\n","                        size=[height_output, width_output],\n","                        mode='bilinear')\n","                else:\n","                    y = y + self.fuse_layers[i][j](x[j])\n","            x_fuse.append(self.relu(y))\n","\n","        return x_fuse\n","\n","\n","blocks_dict = {\n","    'BASIC': BasicBlock,\n","    'BOTTLENECK': Bottleneck\n","}\n","\n","\n","class HighResolutionNet(nn.Module):\n","\n","    def __init__(self, config, **kwargs):\n","        extra = config\n","        super(HighResolutionNet, self).__init__()\n","\n","        # stem net\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn1 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1,\n","                               bias=False)\n","        self.bn2 = BatchNorm2d(64, momentum=BN_MOMENTUM)\n","        self.relu = nn.ReLU(inplace=True)\n","        \n","        self.stage1_cfg = extra['STAGE1']\n","        num_channels = self.stage1_cfg['NUM_CHANNELS'][0]\n","        block = blocks_dict[self.stage1_cfg['BLOCK']]\n","        num_blocks = self.stage1_cfg['NUM_BLOCKS'][0]\n","        self.layer1 = self._make_layer(block, 64, num_channels, num_blocks)\n","        stage1_out_channel = block.expansion*num_channels\n","\n","        self.stage2_cfg = extra['STAGE2']\n","        num_channels = self.stage2_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage2_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition1 = self._make_transition_layer(\n","            [stage1_out_channel], num_channels)\n","        self.stage2, pre_stage_channels = self._make_stage(\n","            self.stage2_cfg, num_channels)\n","\n","        self.stage3_cfg = extra['STAGE3']\n","        num_channels = self.stage3_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage3_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition2 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage3, pre_stage_channels = self._make_stage(\n","            self.stage3_cfg, num_channels)\n","\n","        self.stage4_cfg = extra['STAGE4']\n","        num_channels = self.stage4_cfg['NUM_CHANNELS']\n","        block = blocks_dict[self.stage4_cfg['BLOCK']]\n","        num_channels = [\n","            num_channels[i] * block.expansion for i in range(len(num_channels))]\n","        self.transition3 = self._make_transition_layer(\n","            pre_stage_channels, num_channels)\n","        self.stage4, pre_stage_channels = self._make_stage(\n","            self.stage4_cfg, num_channels, multi_scale_output=True)\n","        \n","        last_inp_channels = np.int(np.sum(pre_stage_channels))\n","\n","        self.last_layer = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=last_inp_channels,\n","                out_channels=last_inp_channels,\n","                kernel_size=1,\n","                stride=1,\n","                padding=0),\n","            BatchNorm2d(last_inp_channels, momentum=BN_MOMENTUM),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(\n","                in_channels=last_inp_channels,\n","                out_channels=1,\n","                kernel_size=extra['FINAL_CONV_KERNEL'],\n","                stride=1,\n","                padding=1 if extra['FINAL_CONV_KERNEL'] == 3 else 0)\n","        )\n","\n","        self.outputs1 = torch.nn.ConvTranspose2d(1,1,4,2,padding = 1)\n","        self.outputs2 = torch.nn.ConvTranspose2d(1,1,4,2,padding = 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def _make_transition_layer(\n","            self, num_channels_pre_layer, num_channels_cur_layer):\n","        num_branches_cur = len(num_channels_cur_layer)\n","        num_branches_pre = len(num_channels_pre_layer)\n","\n","        transition_layers = []\n","        for i in range(num_branches_cur):\n","            if i < num_branches_pre:\n","                if num_channels_cur_layer[i] != num_channels_pre_layer[i]:\n","                    transition_layers.append(nn.Sequential(\n","                        nn.Conv2d(num_channels_pre_layer[i],\n","                                  num_channels_cur_layer[i],\n","                                  3,\n","                                  1,\n","                                  1,\n","                                  bias=False),\n","                        BatchNorm2d(\n","                            num_channels_cur_layer[i], momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=True)))\n","                else:\n","                    transition_layers.append(None)\n","            else:\n","                conv3x3s = []\n","                for j in range(i+1-num_branches_pre):\n","                    inchannels = num_channels_pre_layer[-1]\n","                    outchannels = num_channels_cur_layer[i] \\\n","                        if j == i-num_branches_pre else inchannels\n","                    conv3x3s.append(nn.Sequential(\n","                        nn.Conv2d(\n","                            inchannels, outchannels, 3, 2, 1, bias=False),\n","                        BatchNorm2d(outchannels, momentum=BN_MOMENTUM),\n","                        nn.ReLU(inplace=True)))\n","                transition_layers.append(nn.Sequential(*conv3x3s))\n","\n","        return nn.ModuleList(transition_layers)\n","\n","    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n","            )\n","\n","        layers = []\n","        layers.append(block(inplanes, planes, stride, downsample))\n","        inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def _make_stage(self, layer_config, num_inchannels,\n","                    multi_scale_output=True):\n","        num_modules = layer_config['NUM_MODULES']\n","        num_branches = layer_config['NUM_BRANCHES']\n","        num_blocks = layer_config['NUM_BLOCKS']\n","        num_channels = layer_config['NUM_CHANNELS']\n","        block = blocks_dict[layer_config['BLOCK']]\n","        fuse_method = layer_config['FUSE_METHOD']\n","\n","        modules = []\n","        for i in range(num_modules):\n","            # multi_scale_output is only used last module\n","            if not multi_scale_output and i == num_modules - 1:\n","                reset_multi_scale_output = False\n","            else:\n","                reset_multi_scale_output = True\n","            modules.append(\n","                HighResolutionModule(num_branches,\n","                                      block,\n","                                      num_blocks,\n","                                      num_inchannels,\n","                                      num_channels,\n","                                      fuse_method,\n","                                      reset_multi_scale_output)\n","            )\n","            num_inchannels = modules[-1].get_num_inchannels()\n","\n","        return nn.Sequential(*modules), num_inchannels\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu(x)\n","        x = self.layer1(x)\n","\n","        x_list = []\n","        for i in range(self.stage2_cfg['NUM_BRANCHES']):\n","            if self.transition1[i] is not None:\n","                x_list.append(self.transition1[i](x))\n","            else:\n","                x_list.append(x)\n","        y_list = self.stage2(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage3_cfg['NUM_BRANCHES']):\n","            if self.transition2[i] is not None:\n","                x_list.append(self.transition2[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        y_list = self.stage3(x_list)\n","\n","        x_list = []\n","        for i in range(self.stage4_cfg['NUM_BRANCHES']):\n","            if self.transition3[i] is not None:\n","                x_list.append(self.transition3[i](y_list[-1]))\n","            else:\n","                x_list.append(y_list[i])\n","        x = self.stage4(x_list)\n","\n","        # Upsampling\n","        x0_h, x0_w = x[0].size(2), x[0].size(3)\n","        x1 = F.upsample(x[1], size=(x0_h, x0_w), mode='bilinear')\n","        x2 = F.upsample(x[2], size=(x0_h, x0_w), mode='bilinear')\n","        x3 = F.upsample(x[3], size=(x0_h, x0_w), mode='bilinear')\n","\n","        x = torch.cat([x[0], x1, x2, x3], 1)\n","\n","        x = self.last_layer(x)\n","        x = self.outputs1(x)\n","        x = self.outputs2(x)\n","\n","        x = self.sigmoid(x)\n","\n","        return x\n","\n","    def init_weights(self, pretrained='',):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, std=0.001)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","def get_seg_model(cfg, **kwargs):\n","    model = HighResolutionNet(cfg, **kwargs)\n","    model.init_weights()\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqWpCw_FKFsi","colab_type":"code","outputId":"1c8b29a9-6844-48f8-d90d-a21bfac62f63","executionInfo":{"status":"ok","timestamp":1588035805711,"user_tz":-330,"elapsed":12412,"user":{"displayName":"advait kumar","photoUrl":"","userId":"02777440050749849428"}},"colab":{"base_uri":"https://localhost:8080/","height":178}},"source":["prediction_score('monuseg_unet1.ckpt.t7', 'monuseg_hrnet1.ckpt.t7', test_loader)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2416: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["1st model prediction : 0.5688\n","2nd model prediction : 0.5812\n","Ensemble model with max of outputs prediction : 0.5961\n","Ensemble model with min of outputs prediction : 0.5530\n"],"name":"stdout"}]}]}